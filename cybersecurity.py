# -*- coding: utf-8 -*-
"""Cybersecurity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19pLOpzMxAGyx4Azcv633RA2qMt_EC_Z8
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

from google.colab import drive
drive.mount('/content/drive')

file_path = "/content/drive/MyDrive/Global_Cybersecurity_Threats_2015-2024.csv"
data = pd.read_csv(file_path) # Use pd.read_csv to read a CSV file
print(data.head())

#Print the shape (rows, columns) of the dataset
print("Shape:", data.shape)
#Print all column names
print("Columns:", data.columns.tolist())
#Display the first 5 rows of the dataset
print(data.head())

#Show the count of missing values in each column
print ("Missing Values: \n", data.isnull().sum())

country_counts = data['Country'].value_counts()
plt.figure(figsize=(12, 6))
sns.barplot(x=country_counts.index, y=country_counts.values)
plt.xlabel('Country')
plt.ylabel('Number of Occurrences')
plt.title('Number of Occurrences by Country')
plt.xticks(rotation=90)
plt.show()

plt.figure(figsize=(10, 6))
sns.countplot(y=data['Attack Type'], order=data['Attack Type'].value_counts().index, palette="tab10")
plt.title("Distribution of Attack Types", fontsize=14, fontweight='bold')
plt.xlabel("Count", fontsize=12)
plt.ylabel("Attack Type", fontsize=12)
plt.show()

plt.figure(figsize=(12, 6))
sns.barplot(data=data['Target Industry'].value_counts().reset_index(), x='Target Industry', y='count', palette="PuBu")
plt.title("Targeted Industries in Cybersecurity Threats", fontsize=14, fontweight='bold')
plt.xlabel("Type of Target Industry", fontsize=12)
plt.ylabel("Number of Incidents", fontsize=12)
plt.xticks(rotation=45)
plt.show()

sns.set_style("whitegrid")
sns.set_palette("coolwarm")
plt.figure(figsize=(12, 6))
sns.countplot(x='Attack Source', data=data, palette="coolwarm")
plt.xlabel('Attack Source', fontsize=14, fontweight='bold', color='darkblue')
plt.ylabel('Number of Attacks', fontsize=14, fontweight='bold', color='darkred')
plt.title('Distribution of Attacks by Source', fontsize=16, fontweight='bold', color='purple')
plt.xticks(rotation=45, ha='right', fontsize=12, color='darkgreen')
plt.yticks(fontsize=12, color='darkorange')
plt.show()

plt.figure(figsize=(12, 6))
sns.countplot(x='Security Vulnerability Type', data=data)
plt.xlabel('Security Vulnerability Type')
plt.ylabel('Number of Occurrences')
plt.title('Distribution of Security Vulnerability Types')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))
sns.countplot(x='Defense Mechanism Used', data=data)
plt.xlabel('Defense Mechanism Used')
plt.ylabel('Number of Occurrences')
plt.title('Distribution of Defense Mechanisms Used')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

Country_mapping = {
    'UK': 1, 'Brazil': 2, 'India': 3, 'Japan': 4, 'France': 5, 'Australia': 6,
    'Russia': 7, 'Germany': 8, 'USA': 9, 'China': 10
}

# Apply the mappings to the DataFrame
data['Country'] = data['Country'].map(Country_mapping)

Attack_Type_mapping = {
    'DDoS': 1, 'Phishing': 2, 'SQL Injection': 3, 'Ransomware': 4, 'Malware': 5,
    'Man-in-the-Middle': 6
}

data['Attack Type'] = data['Attack Type'].map(Attack_Type_mapping)

Target_Industry_mapping = {
    'IT': 1, 'Banking': 2, 'Healthcare': 3, 'Retail': 4, 'Education': 5,
    'Government': 6, 'Telecommunications': 7
}

data['Target Industry'] = data['Target Industry'].map(Target_Industry_mapping)

Attack_Source_mapping = {
    'Hacker Group': 1, 'Nation-state': 2, 'Insider': 3, 'Unknown': 4
}

data['Attack Source'] = data['Attack Source'].map(Attack_Source_mapping)

Security_Vulnerability_Type_mapping = {
    'Unpatched Software': 1, 'Weak Passwords': 2, 'Social Engineering': 3, 'Zero-day': 4
}

data['Security Vulnerability Type'] = data['Security Vulnerability Type'].map(Security_Vulnerability_Type_mapping)

mapping = {
    'VPN': 1,
    'Firewall': 2,
    'AI-based Detection': 3,
    'Antivirus': 4,
    'Encryption': 5
}

data['Defense Mechanism Used'] = data['Defense Mechanism Used'].map(mapping)
data.head()

# #Define a list of missing categorical data and fill with "Unknown"
# categorical_cols = [
#     'Defense Mechanism Used',
#     'Security Vulnerability Type',
#     'Attack Source',
#     'Attack Type',
#     'Target Industry'
# ]

# #Loop through each categorical column and fill missing values with 'Unknown'
# for col in categorical_cols:
#     data[col] = data[col].fillna("Unknown")

# #Drop rows where any of the essential numeric values are missing
# data.dropna(subset=['Financial Loss (in Million $)', 'Number of Affected Users', 'Incident Resolution Time (in Hours)', 'Country'], inplace=True)

# #Standardize column names by removing spaces, parentheses, and dollar signs
# data.columns = data.columns.str.replace(' ', '_')
# # data.columns = data.columns.str.replace('(', '')
# # data.columns = data.columns.str.replace(')', '')
# #data.columns = data.columns.str.replace('$', '')

# #Convert 'year' to integer type
# data['year'] = data['Year'].astype(int)
# #Convert 'Financial Loss (in Million $)' to numeric
# data['Financial Loss (in Million $)'] = pd.to_numeric(data['Financial_Loss_in_Million_'], errors='coerce')
# #Convert 'Number_of_Affected_Users' to numeric
# data['Number_of_Affected_Users'] = pd.to_numeric(data['Number_of_Affected_Users'], errors='coerce')
# #Convert 'Incident Resolution Time (in Hours)' to numeric
# data['Incident Resolution Time (in Hours)'] = pd.to_numeric(data['Incident_Resolution_Time_in_Hours'], errors='coerce')

def prepare_data(features):
    X = data[features].values
    y = data['Incident Resolution Time (in Hours)'].values
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_val = scaler.transform(X_val)

    return X_train, X_val, y_train, y_val

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

features = data.columns.tolist()[:-1]
X = data[features].values
y = data['Incident Resolution Time (in Hours)'].values

# Split data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)

# Train the Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

importances = model.coef_

feature_names = features

indices = importances.argsort()[::-1]

plt.figure(figsize=(10, 6))
plt.title("Feature Importances")
plt.bar(range(len(importances)), importances[indices], align="center")
plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45)
plt.tight_layout()
plt.show()

features = ['Country', 'Attack Type','Year']
X_train, X_val, y_train, y_val = prepare_data(features)

from sklearn.impute import SimpleImputer


#Train the regression model
model = LinearRegression()
model.fit(X_train, y_train)

#Predict
y_pred = model.predict(X_val)

#Evaluate the results
mse = mean_squared_error(y_val, y_pred)
r2 = r2_score(y_val, y_pred)
print("Mean Squared Error:", mse)
print("R-squared:", r2)

# Sort values for clean line plots
sorted_idx = np.argsort(y_val)
y_val_sorted = np.array(y_val)[sorted_idx]
y_pred_sorted = np.array(y_pred)[sorted_idx]

plt.figure(figsize=(12, 6))

# Training data (if y_val is training set)
plt.subplot(1, 2, 1)
plt.plot(y_val_sorted, label='Actual', color='blue')
plt.plot(y_pred_sorted, label='Predicted', color='red')
plt.title('Training Data: Actual vs Predicted')
plt.xlabel('Sample Index')
plt.ylabel('Incident Resolution Time (Hours)')
plt.legend()
plt.grid(True)

# Test data (reusing same here for example)
plt.subplot(1, 2, 2)
plt.plot(y_val_sorted, label='Actual', color='blue')
plt.plot(y_pred_sorted, label='Predicted', color='green')
plt.title('Validation Data: Actual vs Predicted')
plt.xlabel('Sample Index')
plt.ylabel('Incident Resolution Time (Hours)')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()









